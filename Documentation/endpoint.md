# API endpoint documentation
We expose our endpoint at /ask.

### The request and responde format
The request format is passed as:
>{
>    "query": ""
>}

Where *query* is the user's question.

The response format is given as:
>{
>    "response": ""
>}

Where *response* is the answer generated by the system.

### The web search tool used
We use SerpAPI for web search capabilities. There was no specific reason for choosing this over other alternatives; it was selected for convenience and ease of integration.

### How the LLM is integrated
The local LLM (Mistral, running through Ollama) is integrated as a *Tool* within the LangChain agent. The agent uses it when the query does not require up-to-date web information, relying on the model's general reasoning and knowledge capabilities.